{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming Queries\n",
    "\n",
    "Get Familiar with querying the database. BUT don't forget your [cheat sheets](https://snowexsql.readthedocs.io/en/latest/cheat_sheet.html)! \n",
    "\n",
    "## Process\n",
    "### Getting Connected\n",
    "Getting connected to the database is easiest done using the snowexsql library function [`get_db`](https://snowexsql.readthedocs.io/en/latest/snowexsql.html#snowexsql.db.get_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to get connect to the db\n",
    "from snowexsql.db import get_db\n",
    "\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the tables classes\n",
    "These are critical for build queries. You will need at least one of these every query since they reflect the data were interested in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.data import SiteData, PointData, LayerData, ImageData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Time!\n",
    "We build queries in python using `session.query()`. Whatever we put inside of the query parentheses is what we will get back in the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what you will use for all of hackweek to access the db\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Lets grab a single row from the points table\n",
    "qry = session.query(PointData).limit(1) # Not super useful for science, but useful for checking to be sure you don't download too much data! \n",
    "# Returns one single point \n",
    "\n",
    "# Execute that query!\n",
    "result = qry.all()\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause for moment and consider what is in `result`....\n",
    "\n",
    "\n",
    "Is it:\n",
    "\n",
    "    A. a single value\n",
    "    B. a bunch of values\n",
    "    C. an object\n",
    "    D. a row of values\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<snowexsql.data.PointData object at 0x7f376451f340>]\n"
     ]
    }
   ],
   "source": [
    "# uncomment the line below and print out the results \n",
    "print(result)\n",
    "# how to get at the value for this data? \n",
    "# got back a single row in the points data table... any column in this row use .value(?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feels soooo *limited* :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "nbsphinx-gallery",
     "nbsphinx-thumbnail"
    ]
   },
   "source": [
    "**Questions**\n",
    "* What happens if we changed the number in the limit? What will we get back?\n",
    "* Where are our column names?\n",
    "* What if I only wanted a single column and not a whole row?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "The database had a silly number of records, and asking for all of them will crash your computer. \n",
    "\n",
    "So let talk about using `.filter()`\n",
    "\n",
    "All queries can be reduced by applying `session.query(__).filter(__)` and a lot can go into the parentheses. This is where your cheat sheet will come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('192.0', '6C10'), ('181.0', '6C10'), ('209.5', '6C10'), ('281.5', '6C10'), ('241.0', '6C10')]\n"
     ]
    }
   ],
   "source": [
    "# This is what you will use for all of hackweek to access the db\n",
    "engine, session = get_db(db_name) # try to bracket this with session.close() as closely as possible as not to be kicked from the database \n",
    "\n",
    "# Its convenient to store a query like the following \n",
    "qry = session.query(LayerData.value, LayerData.site_id) # without .value or others returns object, by specifying multiple returns a tuple\n",
    "\n",
    "# Then filter on it to just density profiles\n",
    "qry = qry.filter(LayerData.type == 'density') # pull density profile \n",
    "qry = qry.filter(LayerData.site_name == 'Grand Mesa') # pull data from location \n",
    "\n",
    "# protect ourselves from a lot of data\n",
    "qry = qry.limit(5) # only pull 5 points \n",
    "\n",
    "result = qry.all()\n",
    "print(result)\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempted this for plotting data from two sites instead of one\n",
    "mica prime gists on github to find solution to later part 7 bonus challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Query missing geometry column 'geom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# protect ourselves from a lot of data\u001b[39;00m\n\u001b[1;32m     14\u001b[0m qry \u001b[38;5;241m=\u001b[39m qry\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# only pull 5 points \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_to_geopandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     18\u001b[0m reult\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/snowexsql/conversions.py:61\u001b[0m, in \u001b[0;36mquery_to_geopandas\u001b[0;34m(query, engine, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m sql \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mstatement\u001b[38;5;241m.\u001b[39mcompile(dialect\u001b[38;5;241m=\u001b[39mpostgresql\u001b[38;5;241m.\u001b[39mdialect())\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Get dataframe from geopandas using the query and engine\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGeoDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_postgis\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/geodataframe.py:724\u001b[0m, in \u001b[0;36mGeoDataFrame.from_postgis\u001b[0;34m(cls, sql, con, geom_col, crs, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_postgis\u001b[39m(\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    666\u001b[0m ):\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03m    Alternate constructor to create a ``GeoDataFrame`` from a sql query\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    containing a geometry column in WKB representation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    geopandas.read_postgis : read PostGIS database to GeoDataFrame\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mgeopandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_postgis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeom_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeom_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/io/sql.py:163\u001b[0m, in \u001b[0;36m_read_postgis\u001b[0;34m(sql, con, geom_col, crs, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# read all in one chunk and return a single GeoDataFrame\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\n\u001b[1;32m    155\u001b[0m         sql,\n\u001b[1;32m    156\u001b[0m         con,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_df_to_geodf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeom_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeom_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# read data in chunks and return a generator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     df_generator \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\n\u001b[1;32m    168\u001b[0m         sql,\n\u001b[1;32m    169\u001b[0m         con,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    175\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/io/sql.py:65\u001b[0m, in \u001b[0;36m_df_to_geodf\u001b[0;34m(df, geom_col, crs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03mTransforms a pandas DataFrame into a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mThe column 'geom_col' must be a geometry column in WKB representation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mGeoDataFrame\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geom_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery missing geometry column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(geom_col))\n\u001b[1;32m     67\u001b[0m geoms \u001b[38;5;241m=\u001b[39m df[geom_col]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m geoms\u001b[38;5;241m.\u001b[39mempty:\n",
      "\u001b[0;31mValueError\u001b[0m: Query missing geometry column 'geom'"
     ]
    }
   ],
   "source": [
    "# Attempted this to plot data on two sites instead of one... \n",
    "# Does not work at the moment \n",
    "\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "from snowexsql.conversions import query_to_geopandas\n",
    "engine, session = get_db(db_name) # try to bracket this with session.close() as closely as possible as not to be kicked from the database \n",
    "\n",
    "# Its convenient to store a query like the following \n",
    "qry = session.query(LayerData.value, LayerData.site_id) # without .value or others returns object, by specifying multiple returns a tuple\n",
    "\n",
    "# Then filter on it to just density profiles\n",
    "qry = qry.filter(LayerData.type == 'density') # pull density profile \n",
    "qry = qry.filter(LayerData.site_name == 'Grand Mesa') # pull data from location \n",
    "qry = qry.filter(LayerData.site_id.in_(['1C14', '1C1']))\n",
    "\n",
    "# protect ourselves from a lot of data\n",
    "qry = qry.limit(2) # only pull 5 points \n",
    "\n",
    "result = query_to_geopandas(qry, engine) \n",
    "print(result)\n",
    "reult.plot()\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* What happens if I filter on a qry that's been filtered?\n",
    "* What happens if I just want a single column/attribute back? How do I do that?\n",
    "\n",
    "### How do I know what to filter on?\n",
    "Queries and `.distinct()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Instruments = None, Mala 1600 MHz GPR, Mala 800 MHz GPR, pulse EKKO Pro multi-polarization 1 GHz GPR, pit ruler, mesa, magnaprobe, camera\n",
      "\n",
      "Available Dates = 2020-05-28, 2020-01-09, 2020-05-23, 2019-11-29, 2020-01-04, 2019-10-20, 2019-11-30, 2020-04-17, 2020-02-19, 2020-02-26, 2020-02-03, 2020-05-05, 2019-10-05, 2019-12-29, 2020-06-02, 2019-10-28, 2020-01-30, 2020-05-22, 2020-03-09, 2019-12-09, 2019-12-28, 2020-02-24, 2020-03-17, 2020-04-01, 2020-05-14, 2019-10-14, 2019-10-29, 2019-10-02, 2020-01-31, 2020-04-18, 2020-04-26, 2019-10-12, 2020-04-29, 2020-02-23, 2020-01-22, 2020-01-01, 2019-11-21, 2020-05-10, 2020-02-12, 2019-11-19, 2020-05-06, 2019-10-25, 2019-11-02, 2020-02-08, 2020-04-14, 2020-04-02, 2019-11-16, 2020-04-07, 2019-12-27, 2019-10-01, 2020-04-16, 2020-06-08, 2019-12-13, 2019-10-17, 2019-10-22, 2020-04-21, 2020-01-03, 2019-12-12, 2019-12-08, 2020-01-25, 2020-02-29, 2019-11-24, 2019-10-18, 2020-05-09, 2020-03-22, 2019-11-06, 2019-12-16, 2020-01-15, 2019-11-22, 2019-10-13, 2019-11-10, 2019-12-06, 2020-02-04, 2019-10-31, 2020-03-07, 2020-04-06, 2020-05-03, 2019-12-10, 2020-05-26, 2019-12-02, 2020-02-13, 2020-02-14, 2020-05-11, 2019-12-01, 2020-01-19, 2019-11-28, 2020-01-17, 2019-12-17, 2019-12-25, 2019-12-14, 2019-10-24, 2020-03-11, 2020-02-01, 2020-02-09, 2020-05-12, 2020-05-25, 2020-03-29, 2020-04-24, 2019-12-11, 2020-01-10, 2020-06-05, 2019-10-10, 2020-04-13, 2020-03-23, 2020-04-23, 2020-05-24, 2019-11-08, 2019-12-26, 2019-12-15, 2020-05-07, 2020-02-28, 2019-11-03, 2020-04-04, 2019-11-27, 2020-03-15, 2019-11-23, 2020-01-16, 2019-10-08, 2019-11-14, 2020-02-15, 2020-02-11, 2019-11-13, 2020-04-30, 2019-10-26, 2020-03-06, 2020-05-31, 2020-03-04, 2019-10-04, 2020-05-16, 2020-04-03, 2019-10-06, 2019-10-09, 2020-03-12, 2019-11-12, 2019-11-01, 2020-03-10, 2019-10-30, 2020-02-21, 2020-06-01, 2020-03-20, 2020-03-03, 2019-11-07, 2020-01-06, 2019-12-22, 2020-01-11, 2019-11-11, 2019-11-05, 2020-01-13, 2019-12-18, 2019-12-30, 2020-05-04, 2020-04-20, 2020-02-22, 2020-05-08, 2019-12-24, 2020-01-24, 2020-04-22, 2019-11-04, 2020-03-31, 2020-01-08, 2020-02-06, 2020-03-05, 2020-03-14, 2020-06-09, 2020-02-20, 2020-04-05, 2020-06-03, 2019-10-16, 2020-04-15, 2019-12-03, 2020-05-30, 2019-11-09, 2020-04-28, 2020-01-12, 2020-05-20, 2020-05-02, 2020-02-05, 2020-01-28, 2020-01-21, 2019-12-19, 2019-10-07, 2020-03-28, 2020-02-10, 2020-03-02, 2019-09-29, 2019-11-15, 2020-01-02, 2020-05-27, 2020-02-18, 2019-10-11, 2019-12-21, 2019-09-30, 2020-04-09, 2020-01-05, 2019-10-27, 2020-04-10, 2020-03-21, 2020-03-16, 2020-02-02, 2020-02-25, 2020-04-08, 2020-01-29, 2019-12-04, 2019-11-26, 2020-03-19, 2020-01-20, 2019-12-31, 2020-02-27, 2020-03-30, 2020-04-25, 2020-01-26, 2020-01-14, 2020-03-01, 2020-02-17, 2020-05-21, 2019-10-23, 2020-04-11, 2019-10-21, 2019-11-25, 2020-04-12, 2020-03-13, 2020-05-01, 2020-03-08, 2020-05-19, 2020-03-27, 2019-11-17, 2020-04-19, 2020-01-23, 2020-05-15, 2020-02-16, 2019-10-19, 2020-05-29, 2020-03-24, 2019-12-07, 2020-02-07, 2020-03-18, 2020-05-17, 2020-05-13, 2019-12-20, 2019-12-23, 2020-06-07, 2020-01-07, 2020-05-18, 2019-12-05, 2019-11-20, 2020-06-06, 2019-11-18, 2020-06-10, 2020-01-27, 2020-01-18, 2020-06-04, 2020-04-27, 2019-10-15, 2020-03-25, 2020-03-26, 2019-10-03\n"
     ]
    }
   ],
   "source": [
    "# This is what you will use for all of hackweek to access the db\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Get the unique datanames in the table\n",
    "results = session.query(PointData.instrument).distinct().all()\n",
    "#print('Available Instruments = {}'.format(', '.join([r[0] for r in results])))\n",
    "print('Available Instruments = {}'.format(', '.join([str(r[0]) for r in results])))\n",
    "\n",
    "\n",
    "# Get the unique instrument in the table\n",
    "#results = session.query(LayerData.instrument).distinct().all()\n",
    "#print('\\nAvailable Instruments = {}'.format(', '.join([str(r[0]) for r in results])))\n",
    "\n",
    "# Get the unique dates in the table\n",
    "results = session.query(PointData.date).distinct().all()\n",
    "print('\\nAvailable Dates = {}'.format(', '.join([str(r[0]) for r in results])))\n",
    "\n",
    "# Get the unique surveyors in the table\n",
    "#results = session.query(LayerData.observers).distinct().all()\n",
    "#print('\\nAvailable surveyors = {}'.format(', '.join([str(r[0]) for r in results])))\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap \n",
    "You just explored using the session object to form queries and compounding filters results with it\n",
    "\n",
    "**You should know:**\n",
    "* How to build queries using filtering\n",
    "* How to isolate column data \n",
    "* Determine what values to filter on\n",
    "\n",
    "If you don't feel comfortable with these, you are probably not alone, let's discuss it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
